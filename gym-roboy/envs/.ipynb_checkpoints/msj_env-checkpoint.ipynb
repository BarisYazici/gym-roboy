{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MsjEnv(gym.GoalEnv):\n",
    "    #metadata = {'render.modes': ['human']}\n",
    "    def __init__(self, n_actions):\n",
    "        self.seed()\n",
    "        #self._env_setup(initial_qpos=initial_qpos)\n",
    "        #self.initial_state = copy.deepcopy(self.sim.get_state())\n",
    "\n",
    "        #max limit position for q\n",
    "        self.max_position = 3.14\n",
    "\n",
    "        #2cm/s for ldot\n",
    "        self.max_speed = 0.02\n",
    "\n",
    "        #why do we need a sample goal -> desired goal for the training environment\n",
    "        #sample goal is the q given\n",
    "        self.goal = self._sample_goal()\n",
    "\n",
    "        #obs is a dictionary which has observation, achieved goal and desired goal. Achieved goal is useful for HER algorithm\n",
    "        obs = self._get_obs()\n",
    "\n",
    "        #ldot is the action space. -2cm/s to 2cm/s\n",
    "        self.action_space = spaces.Box(low=-self.max_speed, high=self.max_speed, shape=(8,), dtype='float32')\n",
    "        \n",
    "        #subscribe to the q and qdot. MSJ has 3 DOF q is a vector of 3. qdot has the same shape as q.\n",
    "        #self.observation_space = spaces.Box(low=self.low_state, high=self.high_state)\n",
    "        #enter the true joint limits\n",
    "        self.observation_space = spaces.Dict(dict(\n",
    "            desired_goal=spaces.Box(-np.inf, np.inf, shape=obs['achieved_goal'].shape, dtype='float32'),\n",
    "            achieved_goal=spaces.Box(-np.inf, np.inf, shape=obs['achieved_goal'].shape, dtype='float32'),\n",
    "            observation=spaces.Box(-np.inf, np.inf, shape=obs['observation'].shape, dtype='float32'),\n",
    "        ))\n",
    "        \n",
    "    # A function to initialize the random generator\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.clip(action, self.action_space.low, self.action_space.high)\n",
    "        self._set_action(action) #set the topic on of target poses\n",
    "        self.sim.step() #unpause the simulation, implement a ROS2 service to command CARDSflow\n",
    "        obs = self._get_obs()\n",
    "\n",
    "        done = False\n",
    "        info = {\n",
    "            'is_success': self._is_success(obs['achieved_goal'], self.goal),\n",
    "        }\n",
    "        reward = self.compute_reward(obs['achieved_goal'], self.goal, info)\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def _set_action(self, action):\n",
    "        assert action.shape == (8,)\n",
    "        #Every ldot should be able to set its own motor.\n",
    "        #Create controller on KinDyn that directly take ldot as a command\n",
    "        pass\n",
    "    def reset(self):\n",
    "        #resetSim\n",
    "        #unpauseSim\n",
    "        #check topic publishers connection\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def _get_obs():\n",
    "        #ROS topics and stuff \n",
    "        #position and velocity of the end effector\n",
    "        #TO-DO subscribe to the q and qdot from ROS1_bridge\n",
    "        robot_qpos, robot_qvel = robot_get_obs(self.sim)\n",
    "        achieved_goal = self._get_achieved_goal().ravel()\n",
    "        observation = np.concatenate([robot_qpos, robot_qvel, achieved_goal])\n",
    "        return {\n",
    "            'observation': observation.copy(),\n",
    "            'achieved_goal': achieved_goal.copy(),\n",
    "            'desired_goal': self.goal.copy(),\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def _get_achieved_goal(self):\n",
    "        goal = [self.sim.data.get_site_xpos(name) for name in FINGERTIP_SITE_NAMES]\n",
    "        return np.array(goal).flatten()\n",
    "    \n",
    "    def compute_reward(self, achieved_goal, goal, info):\n",
    "        d = goal_distance(achieved_goal, goal)\n",
    "        if self.reward_type == 'sparse':\n",
    "            return -(d > self.distance_threshold).astype(np.float32)\n",
    "        else:\n",
    "            return -d\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
